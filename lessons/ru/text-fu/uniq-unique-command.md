---
index: 14
lang: "ru"
title: "uniq (Уникальный)"
meta_title: "uniq (Уникальный) - Text-Fu"
meta_description: "Узнайте, как использовать команду Linux `uniq` для удаления дублирующихся строк из текстовых файлов. Откройте для себя опции, такие как -c, -u, -d, и комбинируйте с `sort` для эффективной очистки данных."
meta_keywords: "команда uniq, Linux uniq, удалить дубликаты, sort uniq, учебник Linux, обработка текста, Linux для начинающих, руководство по Linux"
---

## Lesson Content

Команда `uniq` (unique) — еще один полезный инструмент для анализа текста.

Предположим, у вас есть файл с большим количеством дубликатов:

```plaintext
reading.txt
book
book
paper
paper
article
article
magazine
```

И вы хотите удалить дубликаты; для этого можно использовать команду `uniq`:

```bash
$ uniq reading.txt
book
paper
article
magazine
```

Давайте получим количество вхождений каждой строки:

```bash
$ uniq -c reading.txt
2 book
2 paper
2 article
1 magazine
```

Давайте получим только уникальные значения:

```bash
$ uniq -u reading.txt
magazine
```

Давайте получим только дублирующиеся значения:

```bash
$ uniq -d reading.txt
book
paper
article
```

**Примечание**: `uniq` не обнаруживает дублирующиеся строки, если они не являются смежными. Например:

Предположим, у вас есть файл с дубликатами, которые не являются смежными:

```plaintext
reading.txt
book
paper
book
paper
article
magazine
article
```

```bash
$ uniq reading.txt
reading.txt
book
paper
book
paper
article
magazine
article
```

Результат, возвращаемый `uniq`, будет содержать все записи, в отличие от самого первого примера.

Чтобы преодолеть это ограничение `uniq`, мы можем использовать `sort` в сочетании с `uniq`:

```bash
$ sort reading.txt | uniq
article
book
magazine
paper
```

## Exercise

Практика ведет к совершенству! Вот несколько практических заданий для закрепления вашего понимания обработки текста с помощью `uniq` и `sort`:

1. **[Команда Linux uniq: Фильтрация дубликатов](https://labex.io/ru/labs/linux-linux-uniq-command-duplicate-filtering-219199)** - Узнайте, как использовать команду Linux `uniq` в сочетании с `sort` для идентификации, фильтрации и анализа дублирующихся строк в текстовых файлах.
2. **[Команда Linux sort: Сортировка текста](https://labex.io/ru/labs/linux-linux-sort-command-text-sorting-219196)** - Попрактикуйтесь в использовании команды `sort` для упорядочивания строк текстовых файлов, что является важным шагом перед эффективным использованием `uniq`.
3. **[Подсчет слов и сортировка](https://labex.io/ru/labs/linux-word-count-and-sorting-388125)** - Изучите основные инструменты обработки текста Linux `wc` (подсчет слов) и `sort` в этом практическом задании. Научитесь подсчитывать строки, слова и символы, находить часто встречающиеся шаблоны и эффективно сортировать данные для различных задач анализа текста.

Эти лабораторные работы помогут вам применить концепции в реальных сценариях и обрести уверенность в обработке текста и манипулировании данными в Linux.

## Quiz Question

Какую команду вы бы использовали для удаления дубликатов в файле?

## Quiz Answer

uniq
